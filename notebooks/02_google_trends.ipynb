{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # üìà DataFlip MX - Google Trends Analysis\n",
    "\n",
    "\n",
    "\n",
    " **Objetivo:** Validar demanda real de nichos usando datos de b√∫squeda de Google\n",
    "\n",
    "\n",
    "\n",
    " **Docs:** https://github.com/GeneralMills/pytrends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTAR LIBRER√çAS ===\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURACI√ìN ===\n",
    "# Inicializar pytrends (sin necesidad de API key)\n",
    "pytrends = TrendReq(hl='es-MX', tz=360)\n",
    "\n",
    "# Nichos a analizar (usar los mismos que en Mercado Libre)\n",
    "KEYWORDS = [\n",
    "    \"calculadora financiera\",\n",
    "    \"camara digital vintage\",\n",
    "    \"teclado mecanico\",\n",
    "    \"game boy\",\n",
    "    \"ipod classic\",\n",
    "]\n",
    "\n",
    "# Configuraci√≥n de an√°lisis\n",
    "GEO = 'MX'  # M√©xico\n",
    "TIMEFRAME = 'today 12-m'  # √öltimos 12 meses\n",
    "CATEGORY = 0  # Todas las categor√≠as\n",
    "\n",
    "print(f\"üéØ Analizaremos {len(KEYWORDS)} keywords\")\n",
    "print(f\"üìç Geograf√≠a: M√©xico\")\n",
    "print(f\"üìÖ Per√≠odo: {TIMEFRAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FUNCI√ìN: OBTENER INTER√âS POR TIEMPO ===\n",
    "def get_interest_over_time(keywords: list, timeframe: str = TIMEFRAME, geo: str = GEO):\n",
    "    \"\"\"\n",
    "    Obtiene el inter√©s de b√∫squeda a lo largo del tiempo\n",
    "    \n",
    "    Args:\n",
    "        keywords: Lista de palabras clave (m√°x 5 por request)\n",
    "        timeframe: Per√≠odo de an√°lisis\n",
    "        geo: C√≥digo de pa√≠s\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con datos de tendencias\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pytrends.build_payload(keywords, cat=CATEGORY, timeframe=timeframe, geo=geo)\n",
    "        df = pytrends.interest_over_time()\n",
    "        \n",
    "        if not df.empty and 'isPartial' in df.columns:\n",
    "            df = df.drop('isPartial', axis=1)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error obteniendo datos: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === AN√ÅLISIS: INTER√âS A LO LARGO DEL TIEMPO ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä OBTENIENDO DATOS DE GOOGLE TRENDS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Como Google Trends solo permite 5 keywords por request, dividimos si hay m√°s\n",
    "batches = [KEYWORDS[i:i+5] for i in range(0, len(KEYWORDS), 5)]\n",
    "all_trends = []\n",
    "\n",
    "for i, batch in enumerate(batches, 1):\n",
    "    print(f\"üîç Batch {i}/{len(batches)}: {', '.join(batch)}\")\n",
    "    df_batch = get_interest_over_time(batch)\n",
    "    \n",
    "    if not df_batch.empty:\n",
    "        all_trends.append(df_batch)\n",
    "        print(f\"   ‚úÖ {len(df_batch)} registros obtenidos\")\n",
    "    \n",
    "    # Respetar rate limits\n",
    "    if i < len(batches):\n",
    "        time.sleep(2)\n",
    "\n",
    "# Combinar resultados\n",
    "if all_trends:\n",
    "    df_trends = pd.concat(all_trends, axis=1)\n",
    "    df_trends = df_trends.loc[:, ~df_trends.columns.duplicated()]  # Eliminar duplicados\n",
    "    print(f\"\\n‚úÖ Dataset completo: {df_trends.shape}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No se obtuvieron datos\")\n",
    "    df_trends = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VISUALIZACI√ìN: TENDENCIAS TEMPORALES ===\n",
    "if not df_trends.empty:\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for keyword in df_trends.columns:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_trends.index,\n",
    "            y=df_trends[keyword],\n",
    "            mode='lines',\n",
    "            name=keyword,\n",
    "            line=dict(width=2)\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='üìà Inter√©s de B√∫squeda en Google (√öltimos 12 meses)',\n",
    "        xaxis_title='Fecha',\n",
    "        yaxis_title='Inter√©s Relativo (0-100)',\n",
    "        height=500,\n",
    "        template='plotly_white',\n",
    "        hovermode='x unified',\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"top\",\n",
    "            y=0.99,\n",
    "            xanchor=\"left\",\n",
    "            x=0.01\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === AN√ÅLISIS ESTAD√çSTICO ===\n",
    "if not df_trends.empty:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä ESTAD√çSTICAS DE TENDENCIAS\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    stats = df_trends.describe().T\n",
    "    \n",
    "    # Agregar m√©tricas adicionales\n",
    "    stats['tendencia'] = df_trends.apply(lambda x: np.polyfit(range(len(x)), x, 1)[0])\n",
    "    stats['volatilidad'] = df_trends.std() / df_trends.mean()\n",
    "    stats['estacionalidad'] = df_trends.max() - df_trends.min()\n",
    "    \n",
    "    # Ordenar por inter√©s promedio\n",
    "    stats = stats.sort_values('mean', ascending=False)\n",
    "    \n",
    "    print(stats.round(2))\n",
    "    \n",
    "    # Interpretaci√≥n\n",
    "    print(\"\\nüí° INTERPRETACI√ìN:\")\n",
    "    print(\"   - mean: Inter√©s promedio (m√°s alto = m√°s b√∫squedas)\")\n",
    "    print(\"   - tendencia: Pendiente (positivo = creciendo, negativo = decreciendo)\")\n",
    "    print(\"   - volatilidad: std/mean (alto = b√∫squedas inconsistentes)\")\n",
    "    print(\"   - estacionalidad: Rango max-min (alto = muy estacional)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === B√öSQUEDAS RELACIONADAS ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîó B√öSQUEDAS RELACIONADAS (TOP QUERIES)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "related_queries_all = {}\n",
    "\n",
    "for keyword in KEYWORDS:\n",
    "    try:\n",
    "        pytrends.build_payload([keyword], cat=CATEGORY, timeframe=TIMEFRAME, geo=GEO)\n",
    "        related = pytrends.related_queries()\n",
    "        \n",
    "        if keyword in related and related[keyword]['top'] is not None:\n",
    "            print(f\"\\nüîç {keyword.upper()}\")\n",
    "            top_related = related[keyword]['top']\n",
    "            print(top_related.head(10))\n",
    "            \n",
    "            related_queries_all[keyword] = top_related\n",
    "        \n",
    "        time.sleep(2)  # Rate limiting\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === AN√ÅLISIS GEOGR√ÅFICO (M√âXICO) ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üó∫Ô∏è INTER√âS POR REGI√ìN EN M√âXICO\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "geo_data_all = {}\n",
    "\n",
    "for keyword in KEYWORDS[:3]:  # Solo primeros 3 para no saturar\n",
    "    try:\n",
    "        pytrends.build_payload([keyword], cat=CATEGORY, timeframe=TIMEFRAME, geo=GEO)\n",
    "        geo_data = pytrends.interest_by_region(resolution='REGION', inc_low_vol=True)\n",
    "        \n",
    "        if not geo_data.empty:\n",
    "            top_regions = geo_data.sort_values(keyword, ascending=False).head(10)\n",
    "            print(f\"\\nüìç {keyword.upper()} - Top 10 Estados:\")\n",
    "            print(top_regions)\n",
    "            \n",
    "            geo_data_all[keyword] = geo_data\n",
    "        \n",
    "        time.sleep(2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VISUALIZACI√ìN: HEATMAP DE INTER√âS POR REGI√ìN ===\n",
    "if geo_data_all:\n",
    "    # Tomar primer keyword\n",
    "    first_keyword = list(geo_data_all.keys())[0]\n",
    "    df_geo = geo_data_all[first_keyword].reset_index()\n",
    "    df_geo.columns = ['Estado', 'Interes']\n",
    "    \n",
    "    fig = px.bar(\n",
    "        df_geo.sort_values('Interes', ascending=True).tail(15),\n",
    "        x='Interes',\n",
    "        y='Estado',\n",
    "        orientation='h',\n",
    "        title=f'üó∫Ô∏è Inter√©s por Estado: {first_keyword}',\n",
    "        labels={'Interes': 'Inter√©s Relativo', 'Estado': ''},\n",
    "        height=500,\n",
    "        color='Interes',\n",
    "        color_continuous_scale='Blues'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(template='plotly_white')\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DETECCI√ìN DE ESTACIONALIDAD ===\n",
    "if not df_trends.empty:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìÖ AN√ÅLISIS DE ESTACIONALIDAD\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Agregar columna de mes\n",
    "    df_trends_monthly = df_trends.copy()\n",
    "    df_trends_monthly['mes'] = df_trends_monthly.index.month\n",
    "    \n",
    "    # Promediar por mes\n",
    "    monthly_avg = df_trends_monthly.groupby('mes').mean()\n",
    "    \n",
    "    # Visualizar patr√≥n mensual\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for keyword in monthly_avg.columns:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=monthly_avg.index,\n",
    "            y=monthly_avg[keyword],\n",
    "            mode='lines+markers',\n",
    "            name=keyword,\n",
    "            line=dict(width=2)\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='üìÖ Patr√≥n de B√∫squeda por Mes',\n",
    "        xaxis_title='Mes',\n",
    "        yaxis_title='Inter√©s Promedio',\n",
    "        xaxis=dict(\n",
    "            tickmode='array',\n",
    "            tickvals=list(range(1, 13)),\n",
    "            ticktext=['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', \n",
    "                      'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic']\n",
    "        ),\n",
    "        height=500,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Identificar meses pico\n",
    "    for keyword in monthly_avg.columns:\n",
    "        peak_month = monthly_avg[keyword].idxmax()\n",
    "        low_month = monthly_avg[keyword].idxmin()\n",
    "        print(f\"\\nüîç {keyword}\")\n",
    "        print(f\"   üìà Pico: Mes {peak_month}\")\n",
    "        print(f\"   üìâ Bajo: Mes {low_month}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SCORE DE VOLUMEN (PARA SCORECARD) ===\n",
    "if not df_trends.empty:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚≠ê SCORE DE VOLUMEN DE B√öSQUEDA\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    volume_scores = pd.DataFrame({\n",
    "        'keyword': df_trends.columns,\n",
    "        'interes_promedio': df_trends.mean(),\n",
    "        'tendencia': df_trends.apply(lambda x: np.polyfit(range(len(x)), x, 1)[0]),\n",
    "        'volatilidad': df_trends.std() / df_trends.mean(),\n",
    "    })\n",
    "    \n",
    "    # Normalizar a escala 1-10\n",
    "    volume_scores['score_volumen'] = (\n",
    "        (volume_scores['interes_promedio'] / volume_scores['interes_promedio'].max()) * 10\n",
    "    ).round(2)\n",
    "    \n",
    "    # Penalizar por volatilidad alta\n",
    "    volume_scores['score_consistencia'] = (\n",
    "        10 - (volume_scores['volatilidad'] * 5)\n",
    "    ).clip(1, 10).round(2)\n",
    "    \n",
    "    # Score final\n",
    "    volume_scores['score_final'] = (\n",
    "        volume_scores['score_volumen'] * 0.7 + \n",
    "        volume_scores['score_consistencia'] * 0.3\n",
    "    ).round(2)\n",
    "    \n",
    "    volume_scores = volume_scores.sort_values('score_final', ascending=False)\n",
    "    \n",
    "    print(volume_scores)\n",
    "    \n",
    "    # Visualizar\n",
    "    fig = px.bar(\n",
    "        volume_scores,\n",
    "        x='keyword',\n",
    "        y='score_final',\n",
    "        color='score_final',\n",
    "        title='‚≠ê Score de Volumen de B√∫squeda (Google Trends)',\n",
    "        labels={'score_final': 'Score (1-10)', 'keyword': 'Keyword'},\n",
    "        height=400,\n",
    "        color_continuous_scale='Viridis'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(template='plotly_white', xaxis_tickangle=-45)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EXPORTAR DATOS ===\n",
    "if not df_trends.empty:\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Exportar datos de tendencias\n",
    "    df_trends.to_csv(f'data/processed/trends_timeseries_{timestamp}.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    # Exportar estad√≠sticas\n",
    "    stats.to_csv(f'data/analytics/trends_stats_{timestamp}.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    # Exportar scores\n",
    "    volume_scores.to_csv(f'data/analytics/trends_scores_{timestamp}.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"\\n‚úÖ Datos exportados con timestamp: {timestamp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RECOMENDACIONES FINALES ===\n",
    "if not df_trends.empty:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéØ INSIGHTS DE GOOGLE TRENDS\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    top_keyword = volume_scores.iloc[0]['keyword']\n",
    "    top_score = volume_scores.iloc[0]['score_final']\n",
    "    \n",
    "    print(f\"ü•á KEYWORD #1: {top_keyword}\")\n",
    "    print(f\"   Score: {top_score}/10\")\n",
    "    print(f\"   Inter√©s Promedio: {volume_scores.iloc[0]['interes_promedio']:.2f}\")\n",
    "    \n",
    "    if volume_scores.iloc[0]['tendencia'] > 0:\n",
    "        print(f\"   üìà Tendencia: CRECIENDO (+{volume_scores.iloc[0]['tendencia']:.3f})\")\n",
    "    else:\n",
    "        print(f\"   üìâ Tendencia: DECRECIENDO ({volume_scores.iloc[0]['tendencia']:.3f})\")\n",
    "    \n",
    "    print(\"\\nüìã Pr√≥ximos pasos:\")\n",
    "    print(\"   1. Cruzar estos datos con Mercado Libre\")\n",
    "    print(\"   2. Buscar 'queries relacionadas' con baja competencia\")\n",
    "    print(\"   3. Validar en Reddit si hay demanda cualitativa\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
